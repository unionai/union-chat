cache_workflow:
  hf_secret_key: huggingface-api-key  # update this with the secret key for your huggingface api key

global_config:
  project: <project_name>  # change the project name here
  domain: development  # update this to the desired domain

streamlit:
  resources:
    cpu: "2"
    mem: 3Gi

models:
  - display_name: Qwen2.5 3B
    name: qwen2-5-3b
    model_id: qwen2.5:3b
    llm_runtime:
      llm_type: ollama
      resources:
        cpu: 7
        mem: 25Gi
      scaledown_after: 300
      stream_model: false
      min_replicas: 1
    cache_version: v4
    max_tokens: null

  - display_name: Qwen2.5-1.5B
    name: qwen2-5-1-5b
    model_id: Qwen/Qwen2.5-1.5B
    secret_key: "<endpoint_secret_key>"
    llm_runtime:
      image: ghcr.io/unionai-oss/serving-vllm:0.1.17
      llm_type: vllm
      resources:
        cpu: 7
        mem: 25Gi
        gpu: 1
      accelerator: nvidia-l4
      stream_model: true
      scaledown_after: 300
      env:
        VLLM_DISABLE_COMPILE_CACHE: "1"
    cache_version: v3
    max_tokens: null

  - display_name: Gemma-3-1b-it
    name: gemma-3-1b-it
    model_id: google/gemma-3-1b-it
    secret_key: "<endpoint_secret_key>"
    llm_runtime:
      image: ghcr.io/unionai-oss/serving-sglang:0.1.17
      llm_type: sglang
      resources:
        cpu: 7
        mem: 25Gi
        gpu: 1
      accelerator: nvidia-l4
      stream_model: true
      scaledown_after: 300
      extra_args: --attention-backend flashinfer
    cache_version: v3
    max_tokens: null
